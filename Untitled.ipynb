{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud \n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "Building wheels for collected packages: stop-words\n",
      "  Building wheel for stop-words (setup.py): started\n",
      "  Building wheel for stop-words (setup.py): finished with status 'done'\n",
      "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=31248 sha256=bdc0b6b879f56634e38c8204698fbdc404f6b6841c47676ba1930e6fd6ea3154\n",
      "  Stored in directory: c:\\users\\avinash\\appdata\\local\\pip\\cache\\wheels\\61\\13\\fb\\bde87253355995b963f6355ca563a614453668bfc1b44fdc54\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Avinash\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'Fkq1YtWMXJfm7rqFQe6bUMKnk'\n",
    "consumer_secret = 'tbQFEXaYskF6vfHMN0xpBhjuDGIYP6vpNk4TYEsbn3ETOj6YKY'\n",
    "access_token = '1254116935006072833-4lYrmDIsHq9wbVan3VDtdzwkeWe6Nc'\n",
    "access_token_secret = 'f9zpd5uYABZCiK28Cixp5kR3dy6bFbXybDfwiWRMFvaa3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate= tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "authenticate.set_access_token(access_token,access_token_secret)\n",
    "api= tweepy.API(authenticate, wait_on_rate_limit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)Day 13- Day 22\n",
      "Started revising the java. From primitive and non-primitive data types to interfaces,inheritance,Typecasting- covered all these with practice problems . The idea is to strengthen the core concepts of java before building the open apps. @OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "2)Day 12:\n",
      "Too much reading without coding is not good in the path of learning in the tech world. So, started coding in Java and created the genesis block, first block and second block of the blockchain. Full code from the scratch on GitHub.\n",
      "@OAN_OpenApps #Blockchain \n",
      "#100DaysOfCode\n",
      "\n",
      "3)Day 11:\n",
      "Read about forking - Hard fork and Soft fork in details which also lead to me knowing how Bitcoin cash came into existence. \n",
      "@OAN_OpenApps \n",
      "#Bitcoin #Blockchain #Ethereum\n",
      "#100DaysOfCode\n",
      "\n",
      "4)The hard work put in by the @blockchainedind team in preparing the structure of #100DaysOfCode program is so visible when you are part of the program. Currently I am on Day 20 and I never needed to look for other sources outside of the material they provide.Brilliant!\n",
      "#Blockchain\n",
      "\n",
      "5)Day 10:\n",
      "Jumped to hash function and read about popular hash functions like SHA-256, MD 5, Keccak-256 etc. Also got to know how double spending is tackled in the bitcoin network.\n",
      "@OAN_OpenApps @blockchainedind \n",
      "#blockchain #Bitcoin \n",
      "#100DaysOfCode\n",
      "\n",
      "6)Day 9:\n",
      "On this day, i learnt about symmetric and asymmetric  cryptography, how public and private keys are used and how digital signatures are used to sign transactions.\n",
      "This is a topic of my interest. So went a step further to read about popular algos like AES,DES\n",
      "#100DaysOfCode\n",
      "\n",
      "7)Day 8:\n",
      "This day was characterised by reading about basic #ethereum  terminologies like how gas price and gas limit works.\n",
      "#100DaysOfCode\n",
      "\n",
      "8)Day 7:\n",
      "Learnt about the alternatives of POW. Those are Proof of Stake, proof of Burn, Proof of Capacity, Proof of Elapsed Time and Proof of Activity. POS is gaining much popularity these days as Ethereum 2.0 is implementing it. \n",
      "@OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "9)Day 6:\n",
      "On my way to learn about the open application network, I used this day to understand the core concepts behind the proof-of-work, the advantages it provide, the challenges and the threats behind using this protocol.\n",
      "@OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "10)Day 5:\n",
      "This day was invested in understanding the block anatomy like nonce, merkle tree, timestamp etc and an overview of consensus mechanism followed by the network.\n",
      "#100DaysOfCode\n",
      "\n",
      "11)Day 4:\n",
      "Permissioned blockchains always gave tough time to me. So decided to invest this day to clear all my doubts regarding how group of organisations also can regulate the blockchain for the specific use cases albeit it raises question over decentralisation.\n",
      "#100DaysOfCode\n",
      "\n",
      "12)@RobotProud Thanks Robot\n",
      "\n",
      "13)Day 3:\n",
      "Dived deeper into the concepts of how candidate blocks work by collecting transactions, the nonce, the public and private blockchains. Also covered how blockchain is being used in industries for voting, supply chain, digital certificates etc.\n",
      "#100DaysOfCode\n",
      "\n",
      "14)Day 2:\n",
      "Jumped into bitcoin mining part and the consensus algorithm used in the network. The miners are awarded for the resources they use to compute the complex mathematical problem and receive the reward which is halved after every 210000 + transaction fees.\n",
      "#100DaysOfCode\n",
      "\n",
      "15)Day 1:\n",
      "The content of the first day focussed on Bitcoin and how it paved the way for other applications in blockchain over the years, how blockchain is different from centralised systems, distributed ledger and transaction verification.\n",
      "#100DaysOfCode\n",
      "\n",
      "16)Thread:\n",
      "#100DaysOfCode under @blockchainedind @OAN_OpenApps \n",
      "The onboarding of 40+ selected students and professionals happened on 2nd oct where we were introduced to each other. The session also laid emphasis on the relevance and significance of open application networks .\n",
      "\n",
      "17)The ongoing #covid19 has also seen the rise of number of scams in the name of internships. Apparently, students are asked to sell some courses and are awarded internship certificates. What the hell am I supposed to do with that certificate? Can't even flaunt.\n",
      "\n",
      "18)RT @Melt_Dem: 1/ the crypto fundraising scene is *crazy* right now. \n",
      "\n",
      "there's so much money chasing every deal, so many new funds, and ever\n",
      "\n",
      "19)That phase of the life when I started learning #MachineLearning . Finally I think now I am eligible enough to write 'Machine Learning Enthusiast' in my bio.\n",
      "\n",
      "20)When nobody is attending your webinar, call  google, employees and organise a webinar with a fancy poster titled- \"How to get job in google\". It will surely work.\n",
      "#Trends\n",
      "\n",
      "21)Are you even a cofounder if you are not virtue signalling on @LinkedIn with 500 words posts regularly?\n",
      "\n",
      "22)RT @aparanjape: M.S. Dhoni - a great compilation by @Amul_Coop \n",
      "\n",
      "https://t.co/67cP7qj1SL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts = api.user_timeline(screen_name = 'avi_avi_nash', count = 100, lang='en',tweet_mode=\"extended\")\n",
    "i=1\n",
    "for tweet in posts[0:22]:\n",
    "    print(str(i)+\")\"+tweet.full_text+\"\\n\")\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day 13- Day 22\\nStarted revising the java. Fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 12:\\nToo much reading without coding is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day 11:\\nRead about forking - Hard fork and So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hard work put in by the @blockchainedind t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day 10:\\nJumped to hash function and read abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  Day 13- Day 22\\nStarted revising the java. Fro...\n",
       "1  Day 12:\\nToo much reading without coding is no...\n",
       "2  Day 11:\\nRead about forking - Hard fork and So...\n",
       "3  The hard work put in by the @blockchainedind t...\n",
       "4  Day 10:\\nJumped to hash function and read abou..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.DataFrame([tweet.full_text for tweet in posts],columns=['Tweets'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet): \n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweets']= data['Tweets'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day 13 Day 22 Started revising the java From p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 12 Too much reading without coding is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day 11 Read about forking Hard fork and Soft f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hard work put in by the team in preparing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day 10 Jumped to hash function and read about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day 9 On this day i learnt about symmetric and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Day 8 This day was characterised by reading ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Day 7 Learnt about the alternatives of POW Tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Day 6 On my way to learn about the open applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day 5 This day was invested in understanding t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Day 4 Permissioned blockchains always gave tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thanks Robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Day 3 Dived deeper into the concepts of how ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Day 2 Jumped into bitcoin mining part and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Day 1 The content of the first day focussed on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thread 100DaysOfCode under OpenApps The onboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The ongoing covid19 has also seen the rise of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT Dem 1 the crypto fundraising scene is crazy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>That phase of the life when I started learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>When nobody is attending your webinar call goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Are you even a cofounder if you are not virtue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT M S Dhoni a great compilation by Coop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>io This is brilliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT Interacting with our bright young minds at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>comment interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT Das Kapital in a nutshell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hackout Hackoffv2 0 HackJaipur Last year i sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT Let s clear this misinformation This is com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT Also submit this RTI reply from RBI and spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I have a joke on my university but it might in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ratna Bitcoin price post halving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RT ratna The case for censorship resistant mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RT Twitter comments gt gt gt Original tweet Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>This decade will see the growth of matic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>So it turned out that the coins which were ina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What So are we going to know who Satoshi Nakam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Many are losing their faith in Bitcoin as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RT Bitcoin 2018 DeFi is bullshit 2020 Bitcoin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RT 0 Web 3 Power pack guide All the budding De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Others I am the jack of all ships master of no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>rowling Now waiting for your own wallet whose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Decentralised world is on its way Bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>If you like tech talks more than ted talks the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I like this idea of issuing the ERC20 tokens a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>This is huge Tokens MOONS and BRICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RT Jhaveri Economic Package for Migrants FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RT Jhaveri Economic Package for Migrants Big f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>I take back my words Online exams are even big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RT Jhaveri Update India has now ramped the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>First they ignore you Then they laugh at you T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RT Mainnet is going live The launch sequence s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ratna Came to know about your journey with and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Insightful event Found it more interesting bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Besides political twitter there is another sid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Those who question Bitcoin and refuse to accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>From 12 to 8500 and still going the success st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>This was my first bitcoinhalving The last bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>On the first BitcoinHalving in 2012 bitcoin pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Doesn t look like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24 hours 164 blocks into Bitcoin halving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets\n",
       "0   Day 13 Day 22 Started revising the java From p...\n",
       "1   Day 12 Too much reading without coding is not ...\n",
       "2   Day 11 Read about forking Hard fork and Soft f...\n",
       "3   The hard work put in by the team in preparing ...\n",
       "4   Day 10 Jumped to hash function and read about ...\n",
       "5   Day 9 On this day i learnt about symmetric and...\n",
       "6   Day 8 This day was characterised by reading ab...\n",
       "7   Day 7 Learnt about the alternatives of POW Tho...\n",
       "8   Day 6 On my way to learn about the open applic...\n",
       "9   Day 5 This day was invested in understanding t...\n",
       "10  Day 4 Permissioned blockchains always gave tou...\n",
       "11                                       Thanks Robot\n",
       "12  Day 3 Dived deeper into the concepts of how ca...\n",
       "13  Day 2 Jumped into bitcoin mining part and the ...\n",
       "14  Day 1 The content of the first day focussed on...\n",
       "15  Thread 100DaysOfCode under OpenApps The onboar...\n",
       "16  The ongoing covid19 has also seen the rise of ...\n",
       "17  RT Dem 1 the crypto fundraising scene is crazy...\n",
       "18  That phase of the life when I started learning...\n",
       "19  When nobody is attending your webinar call goo...\n",
       "20  Are you even a cofounder if you are not virtue...\n",
       "21           RT M S Dhoni a great compilation by Coop\n",
       "22                               io This is brilliant\n",
       "23  RT Interacting with our bright young minds at ...\n",
       "24                                 comment interested\n",
       "25                       RT Das Kapital in a nutshell\n",
       "26  Hackout Hackoffv2 0 HackJaipur Last year i sta...\n",
       "27  RT Let s clear this misinformation This is com...\n",
       "28  RT Also submit this RTI reply from RBI and spe...\n",
       "29  I have a joke on my university but it might in...\n",
       "..                                                ...\n",
       "69                   ratna Bitcoin price post halving\n",
       "70  RT ratna The case for censorship resistant mon...\n",
       "71  RT Twitter comments gt gt gt Original tweet Al...\n",
       "72           This decade will see the growth of matic\n",
       "73  So it turned out that the coins which were ina...\n",
       "74  What So are we going to know who Satoshi Nakam...\n",
       "75  Many are losing their faith in Bitcoin as the ...\n",
       "76  RT Bitcoin 2018 DeFi is bullshit 2020 Bitcoin ...\n",
       "77  RT 0 Web 3 Power pack guide All the budding De...\n",
       "78  Others I am the jack of all ships master of no...\n",
       "79  rowling Now waiting for your own wallet whose ...\n",
       "80          Decentralised world is on its way Bitcoin\n",
       "81  If you like tech talks more than ted talks the...\n",
       "82  I like this idea of issuing the ERC20 tokens a...\n",
       "83               This is huge Tokens MOONS and BRICKS\n",
       "84  RT Jhaveri Economic Package for Migrants FREE ...\n",
       "85  RT Jhaveri Economic Package for Migrants Big f...\n",
       "86  I take back my words Online exams are even big...\n",
       "87  RT Jhaveri Update India has now ramped the pro...\n",
       "88  First they ignore you Then they laugh at you T...\n",
       "89  RT Mainnet is going live The launch sequence s...\n",
       "90  ratna Came to know about your journey with and...\n",
       "91  Insightful event Found it more interesting bec...\n",
       "92  Besides political twitter there is another sid...\n",
       "93  Those who question Bitcoin and refuse to accep...\n",
       "94  From 12 to 8500 and still going the success st...\n",
       "95  This was my first bitcoinhalving The last bloc...\n",
       "96  On the first BitcoinHalving in 2012 bitcoin pr...\n",
       "97                                  Doesn t look like\n",
       "98           24 hours 164 blocks into Bitcoin halving\n",
       "\n",
       "[99 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis Tool\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "import operator\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'positive-words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b7c9587aa5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'positive-words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative-words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-b7c9587aa5dc>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positive-words.txt'"
     ]
    }
   ],
   "source": [
    "#a=input(\"Provide a file directory\")\n",
    "a=data\n",
    "\n",
    "def read_file(file=a):\n",
    "    file=open(file,'r')\n",
    "    text=file.read().lower()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "positive=read_file('positive-words.txt').split('\\n')\n",
    "negative=read_file('negative-words.txt').split('\\n')\n",
    "p=0\n",
    "pintxt=[]\n",
    "n=0\n",
    "nintxt=[]\n",
    "e=0  #neutralne\n",
    "eintxt=[]\n",
    "\n",
    "b= read_file()\n",
    "\n",
    "def file_to_sentences(text=b):\n",
    "    text=text.replace(\",\",\" \")\n",
    "    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)\n",
    "    return sentences\n",
    "sentences=file_to_sentences()\n",
    "\n",
    "def file_to_text(file=b):\n",
    "    file=file.translate(str.maketrans('','',string.punctuation)).lower()\n",
    "    file=file.split()\n",
    "    return file\n",
    "text=file_to_text()\n",
    "\n",
    "for i in text:\n",
    "    if i in positive:\n",
    "        p+=1\n",
    "        pintxt.append(i)\n",
    "    elif i in negative:\n",
    "        n+=1\n",
    "        nintxt.append(i)\n",
    "    else:\n",
    "        e+=1\n",
    "        eintxt.append(i)\n",
    "\n",
    "def procent(object,text):\n",
    "    m=object/len(text)*100\n",
    "    m=format(float(m),'.2f')\n",
    "    return m+'%'\n",
    "def print_percentage():\n",
    "    print('Sentiment distribution for',a)\n",
    "    print('Positive:', procent(p, text), 'Negative:', procent(n, text), 'Neutral:' + procent(e, text))\n",
    "def pie_chart():\n",
    "    dane=[p,n,e]\n",
    "    labels=['Positive','Negative','Neutral']\n",
    "    plt.pie(dane,labels=labels,autopct='%1.2f%%',colors=['g','r','gold'])\n",
    "    k='Sentiment Analysis for: '+a\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "counterp = collections.Counter(pintxt)\n",
    "countern = collections.Counter(nintxt)\n",
    "pmc=counterp.most_common()#positive most common\n",
    "nmc=countern.most_common()#negative most common\n",
    "\n",
    "#sortowanie list malejco\n",
    "pmc.sort(key=operator.itemgetter(1),reverse=True)\n",
    "nmc.sort(key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "#funkcja drukuje podan ilo najpopularniejszych pozytywnych s贸w w tekcie.\n",
    "#domylnie podaje list wszystkich pozytywnych s贸w jakie wystpiy w tekie\n",
    "def pos_words_list(n=len(pmc)):\n",
    "    sowo = [x[0] for x in pmc]\n",
    "    ilo = [x[1] for x in pmc]\n",
    "    for i in range(n):\n",
    "        print(\"{:-<15} {}\".format(sowo[i], ilo[i]))\n",
    "\n",
    "#funkcja drukuje podan ilo najpopularniejszych negatywnych s贸w w tekcie.\n",
    "#domylnie podaje list wszystkich negatywnych s贸w jakie wystpiy w tekie\n",
    "def neg_words_list(n=len(nmc)):\n",
    "    sowo = [x[0] for x in nmc]\n",
    "    ilo = [x[1] for x in nmc]\n",
    "    for i in range(n):\n",
    "        print(\"{:-<15} {}\".format(sowo[i], ilo[i]))\n",
    "\n",
    "\n",
    "def top_5_words(list):\n",
    "    x_val = [x[0] for x in list]\n",
    "    if len(list)>5:\n",
    "        top_5_words=[]\n",
    "        for i in range(5):\n",
    "            top_5_words.append(x_val[i])\n",
    "        return top_5_words\n",
    "    else:\n",
    "        return x_val\n",
    "\n",
    "def top_5_numbers(list):\n",
    "    y_val = [x[1] for x in list]\n",
    "    if len(list)>5:\n",
    "        top_5_numbers=[]\n",
    "        for i in range(5):\n",
    "            top_5_numbers.append(y_val[i])\n",
    "        return top_5_numbers\n",
    "    else:\n",
    "        return y_val\n",
    "\n",
    "def pos_chart():\n",
    "    plt.bar(top_5_words(pmc),top_5_numbers(pmc),color='g')\n",
    "    plt.show()\n",
    "\n",
    "def neg_chart():\n",
    "    plt.bar(top_5_words(nmc),top_5_numbers(nmc),color='r')\n",
    "    plt.show()\n",
    "\n",
    "text1=file_to_text(b)\n",
    "def stopped_text(text1=text1):\n",
    "    for i in text1:\n",
    "        if i in stop_words:\n",
    "            text1.remove(i)\n",
    "    return text1\n",
    "\n",
    "stop = stopped_text()\n",
    "ps=0\n",
    "ns=0\n",
    "es=0\n",
    "for i in stop:\n",
    "    if i in positive:\n",
    "        ps+=1\n",
    "    elif i in negative:\n",
    "        ns+=1\n",
    "    else:\n",
    "        es+=1\n",
    "\n",
    "def print_stop_percentage():\n",
    "    print('Sentiment distribution for',a,'without stop words')\n",
    "    print('Positive:', procent(ps, stop), 'Negative:', procent(ns, stop), 'Neutral:' + procent(es, stop))\n",
    "\n",
    "def pie_stop_chart():\n",
    "    dane=[ps,ns,es]\n",
    "    labels=['Positive','Negative','Neutral']\n",
    "    plt.pie(dane,labels=labels,autopct='%1.2f%%',colors=['g','r','gold'])\n",
    "    k=('Sentiment Analysis without stop words for: '+a)\n",
    "    print(k)\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "\n",
    "def sent_key(key):\n",
    "    key_list=[]\n",
    "    for sentence in sentences:\n",
    "        c=sentence.split()\n",
    "        if key in c:\n",
    "            key_list.append(sentence)\n",
    "    str=''.join(key_list)\n",
    "    key_list=str.split()\n",
    "    return key_list\n",
    "\n",
    "q=True\n",
    "while q:\n",
    "    print(\"\"\"What do you want to do?\n",
    "1 - show sentiment distribution in a text\n",
    "2 - show a pie chart of sentiment distribution\n",
    "3 - show a list of all positive words\n",
    "4 - show a list of all negative words\n",
    "5 - show a chart with top positive words\n",
    "6 - show a chart with top negative words\n",
    "7 - show sentiment distribution for text without redundant words\n",
    "8 - show a pie chart of sentiment distribution for text without redundant words\n",
    "9 - show sentiment distribution for sentences with provided keyword\n",
    "10 - quit \"\"\")\n",
    "    q=int(input(\"\"\"Press the number:\"\"\"))\n",
    "    if q==1:\n",
    "       print_percentage()\n",
    "    elif q == 2:\n",
    "        pie_chart()\n",
    "    elif q == 3:\n",
    "        pos_words_list()\n",
    "    elif q == 4:\n",
    "        neg_words_list()\n",
    "    elif q == 5:\n",
    "        pos_chart()\n",
    "    elif q == 6:\n",
    "        neg_chart()\n",
    "    elif q == 7:\n",
    "        print_stop_percentage()\n",
    "    elif q == 8:\n",
    "        pie_stop_chart()\n",
    "    elif q == 9:\n",
    "        key = input(\"Provide a keyword:\").lower()\n",
    "        pk = 0\n",
    "        nk = 0\n",
    "        ek = 0\n",
    "        key_list=sent_key(key)\n",
    "        if len(key_list)>0:\n",
    "            for i in key_list:\n",
    "                if i in positive:\n",
    "                    pk += 1\n",
    "                elif i in negative:\n",
    "                    nk += 1\n",
    "                else:\n",
    "                    ek += 1\n",
    "            print('Sentiment distribution for',a,'for sentences with key word')\n",
    "            print('Positive:', procent(pk, key_list), 'Negative:', procent(nk, key_list), 'Neutral:' + procent(ek, key_list))\n",
    "        else:\n",
    "            print(\"The word does not occur\")\n",
    "    elif q == 10:\n",
    "        print(\"Adi贸s!\")\n",
    "        q=None\n",
    "    else:\n",
    "        print(\"Sorry, I don't understand.Provide a number from 1 to 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
